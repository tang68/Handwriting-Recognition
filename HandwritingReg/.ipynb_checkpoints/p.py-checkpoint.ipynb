{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist \n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense  \n",
    "from keras.layers import Dropout  \n",
    "from keras.layers import Flatten  \n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib. pyplot as plt \n",
    "from matplotlib import pyplot as plt\n",
    "from keras.layers.convolutional import Conv2D  \n",
    "from keras.layers.convolutional import MaxPooling2D  \n",
    "from keras.utils import np_utils \n",
    "from keras import backend as K \n",
    "K.set_image_dim_ordering ( 'th' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Divided the data into subsets of training and testing.\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data( )\n",
    "# Since we are working in gray scale we can\n",
    "# set the depth to the value 1.\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28 ).astype('float32')\n",
    "# We normalize our data according to the\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# Converts y_train and y_test, which are class vectors, to a binary class array (one-hot vectors)\n",
    "y_train = np_utils. to_categorical(y_train)\n",
    "y_test = np_utils. to_categorical(y_test)\n",
    "# Number of digit types found in MNIST. In this case, the value is 10, corresponding to (0,1,2,3,4,5,6,7,8,9).\n",
    "num_classes = y_test.shape [1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deeper_cnn_model():\n",
    "    model = Sequential ( )\n",
    "    model.add(Conv2D (30, ( 5, 5 ), input_shape = ( 1 , 28 , 28 ), activation = 'relu' ) )\n",
    "    model.add(MaxPooling2D ( pool_size = ( 2 , 2 )))\n",
    "    model.add(Conv2D (15, (3, 3), activation = 'relu' ) )\n",
    "    model.add(MaxPooling2D ( pool_size = ( 2 , 2 ) ) )\n",
    "    model.add(Dropout ( 0.2 ) )\n",
    "    model.add(Flatten ( ) )\n",
    "    model.add(Dense ( 128 , activation = 'relu' ) )\n",
    "    model.add(Dense ( 64 , activation = 'relu' ) )\n",
    "    model.add(Dense ( 32 , activation = 'relu' ) )\n",
    "    model.add(Dense ( num_classes, activation = 'softmax' , name = 'predict' ) )\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = deeper_cnn_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 228s 4ms/step - loss: 0.0390 - acc: 0.9871 - val_loss: 0.0333 - val_acc: 0.9893\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0309 - acc: 0.9899 - val_loss: 0.0305 - val_acc: 0.9907\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 238s 4ms/step - loss: 0.0295 - acc: 0.9907 - val_loss: 0.0272 - val_acc: 0.9912\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 248s 4ms/step - loss: 0.0251 - acc: 0.9918 - val_loss: 0.0284 - val_acc: 0.9915\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 228s 4ms/step - loss: 0.0225 - acc: 0.9923 - val_loss: 0.0269 - val_acc: 0.9917\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 227s 4ms/step - loss: 0.0227 - acc: 0.9927 - val_loss: 0.0252 - val_acc: 0.9921\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 209s 3ms/step - loss: 0.0203 - acc: 0.9936 - val_loss: 0.0252 - val_acc: 0.9929\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0189 - acc: 0.9938 - val_loss: 0.0257 - val_acc: 0.9922\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0177 - acc: 0.9942 - val_loss: 0.0282 - val_acc: 0.9925\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 175s 3ms/step - loss: 0.0173 - acc: 0.9946 - val_loss: 0.0290 - val_acc: 0.9914\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 175s 3ms/step - loss: 0.0161 - acc: 0.9950 - val_loss: 0.0279 - val_acc: 0.9921\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 175s 3ms/step - loss: 0.0147 - acc: 0.9953 - val_loss: 0.0308 - val_acc: 0.9911\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 175s 3ms/step - loss: 0.0153 - acc: 0.9949 - val_loss: 0.0277 - val_acc: 0.9915\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 176s 3ms/step - loss: 0.0158 - acc: 0.9950 - val_loss: 0.0226 - val_acc: 0.9940\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0142 - acc: 0.9952 - val_loss: 0.0275 - val_acc: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1837143910>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=15, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc: 99.30%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate ( X_test , y_test, verbose = 0 )\n",
    "print ( \"\\nacc: %.2f%%\" % (scores[1] * 100)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1838be5250>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1837d7ab10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_pred = cv2.imread ('num5.png', cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img_pred, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 'with probability of', '100.00 %')\n"
     ]
    }
   ],
   "source": [
    "if img_pred.shape != [ 28 , 28 ]:\n",
    "    img2 = cv2.resize ( img_pred, ( 28 , 28 ) )\n",
    "    img_pred = img2.reshape ( 28 , 28 , - 1 ) ;\n",
    "else :\n",
    "    img_pred = img_pred.reshape ( 28 , 28 , - 1 ) ;\n",
    "    \n",
    "# here also we inform the value for the depth = 1, number of rows and columns, which correspond 28x28 of the image.\n",
    "img_pred = img_pred.reshape( 1 , 1 , 28 , 28 )\n",
    "pred = model.predict_classes(img_pred)\n",
    "pred_proba = model.predict_proba ( img_pred )\n",
    "pred_proba = \"%.2f %%\" % (pred_proba[0][pred] * 100) \n",
    "print (pred[0] , \"with probability of\" , pred_proba )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
